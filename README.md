# 3Dリバーシの対戦AIの設計(UIは無視)
author: zodiac-G12

## 技術的概要
### 第一目標
- ~~2Dにおける評価関数を用いた簡単なAI~~ 完了

### 第二目標
- ~~2Dにおける高度なAIの作成~~
  - ~~αβ法とかmini-max法とか~~ 完了。モンテカルロ木探索で強いのが出来た

### 第三目標
- 2Dの実装を3Dに拡張

### 最終目標
- ~~DQN(怖くないよ)を用いてやってみたい~~ 評価空間でかすぎ問題なので断念無念また明日👋

## 問題点
- 作成された前例がない
  - アルゴリズムも公開例が殆ど至るところで存在しない
  - ~~別AIとの対戦も難関~~ そうでもない(Ex.Rand君)
  - ~~何を以て強いかという判断も難関~~ そうでもない(Ex.他のAIと戦わせてイタチごっこ的に証明できる)
- 対戦に時間がかかるので、検証にも時間を要する
- 1点に於いて判定線分が13線分上で成されるので、次元数が高次元となる
  - 高速なアルゴリズムを考案する必要性

## 進捗
- 2Dの対人オセロゲームは完成
- rand関数を用いたAI名づけて"Rand君"と対戦できるようになった
- Rand君1 vs. Rand君2で対戦させて、貴方は観客として傍観することができる
- Semi学君という、盤面評価関数とε-グリーディ法を組み合わせたAIを作成(Rand君相手に約85%の勝率)
- Bakuchi君という、モンテカルロ木探索+Semi学くん+角取り+デスゾーン取らないガルマッゾみたいなAI(Rand君相手に約95%の勝率) くいなちゃんには勝てたことがない

## 次の段階
- Rand君と蝉(SEMI)学くんを戦わせて、蝉学君はボードの価値を一局ごとに記憶する。
ボードの各マスの値を見て、値が最大となる手を打つようにする。
つまりは、勝った時に打った譜面を「+1」、負けた時の譜面を「-1」して次局で生かす。
相手の打った譜面に於いても同様にして記憶する.負けた時に打たれた譜面を「-1」、
勝った時に討たれた譜面を「+1」する。打たれたら嫌な譜面を覚えて、そこに駒を
置くようにする。
  - 人間 vs. 蝉学君バージョンもあり(こっちの方が多分強くなる)
  - だが、この場合だと、必ずしも最善手を打てるとは限らない。
	まぐれで自分が勝った場合や、まぐれで相手が負けた場合はノイズとなる(煉獄爆音協奏曲)。
